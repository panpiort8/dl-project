{
    "name": "fpt",

    "params": {
        "task": "bit-xor",
        "n": 100,
        "num_patterns": 2,
        "patch_size": null,
        
        "model_name": "gpt2",
        "pretrained": true,
        
        "freeze_trans": true,
        "freeze_in": false,
        "freeze_pos": true,
        "freeze_ln": false,
        "freeze_attn": true,
        "freeze_ff": true,
        "freeze_out": false,
        
        "in_layer_size": null,
        "out_layer_size": null,
        
        "learning_rate": 0.001,
        "batch_size": 25,
        "dropout": 0.1,
        "orth_gain": 1.41
    },
    
    "args": {
        "num_iters": 50,
        "steps_per_iter": 100,
        "test_steps_per_iter": 25,
        "log_to_wandb": true,
        "note": "",
        "wandb_project": "universal-computation-engine",
        "wandb_entity": "dl-project2",
        "include_date": true,
        "save_models": false,
        "save_models_ever": 25,
        "device": "cuda",
        "gpu_batch_size": 25
    }
}
